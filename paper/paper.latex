%%%% Proceedings format for most of ACM conferences (with the exceptions listed below) and all ICPS volumes.
\documentclass[sigconf]{acmart}
%%%% As of March 2017, [siggraph] is no longer used. Please use sigconf (above) for SIGGRAPH conferences.

%%%% Proceedings format for SIGPLAN conferences 
% \documentclass[sigplan, anonymous, review]{acmart}

%%%% Proceedings format for SIGCHI conferences
% \documentclass[sigchi, review]{acmart}

%%%% To use the SIGCHI extended abstract template, please visit
% https://www.overleaf.com/read/zzzfqvkmrfzn


\usepackage{booktabs} % For formal tables
\usepackage{subcaption}


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
% setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}
% \editor{Derrick Amponsa Afrifa}
% \editor{Luke Matthew Lau}
% \editor{Martino Mansoldo}


\begin{document}
% We need a short and succinct title
\title{CycleGAN Two Ways}
\subtitle{A Comparison of Unpaired Image-to-Image Translation Performance with Cycle-Consistent Adversarial Networks implemented with various Machine Learning frameworks}
\subtitlenote{The full version of the author's guide is available as
  \texttt{acmart.pdf} document}


\author{Derrick Amponsa Afrifa}
\affiliation{%
  \institution{Trinity College, University of Dublin}
  \city{Dublin}
  \state{Republic of Ireland}
}
\email{afrifad@tcd.ie}

\author{Luke Lau}
\affiliation{%
  \institution{Trinity College, University of Dublin}
  \city{Dublin}
  \state{Republic of Ireland}
}
\email{laulu@tcd.ie}

\author{Martino Mansoldo}
\affiliation{%
  \institution{Trinity College, University of Dublin}
  \city{Dublin}
  \country{Republic of Ireland}}
\email{mansoldm@tcd.ie}

\begin{abstract}
Although many Machine Learning libraries and frameworks implement the same set of algorithms, the manner in which they are implemented differs from library to library. One rarely finds objectively superior implementations. However, a number of key metrics can be used to evaluate the strengths and shortcomings of dissimilar approaches. This paper attempts to outline the differences in performance that result from distinct CycleGAN\cite{cyclegan} algorithms. Models are trained using the same data sets and key aspects of their performance are delineated. It is expected that an understanding of the nature of the differences will reveal new optimisation avenues.

% \break
% 1.Introduction. In one sentence, what's the topic?\break
% 2.State the problem you tackle\break
% 3.Summarize (in one sentence) why nobody else has adequately answered the research question yet\break
% 4.Explain, in one sentence, how you tackled the research question\break
% 5.In one sentence, how did you go about doing the research that follows from your big idea.\break
% 6.As a single sentence, what's the key impact of your research
\footnote{This is an abstract footnote}
\end{abstract}

\keywords{machine learning, neural networks, generative adversarial networks, tensorflow, pytorch}


\maketitle

\section{Introduction}
Generative Adversarial Networks (GANs) are a type of neural network, based around the architecture of a generator and discriminator competing against each other.
The generator tries to generate images from noise that are similar to the training data, whilst the discriminator tries to catch out the generator and distinguish the "fake" generated images from the real images.
CycleGAN\cite{cyclegan} builds upon this by having two generators that translate images between two categories, $G: X \rightarrow Y$ and $F: Y \rightarrow X$. Additionally, it adds a cycle-consistency loss, where images are converted over and back to their original category and the difference is minimised, so that $F(G(X)) \approx X$ holds.
The original implementation that accompanied the paper was in \href{https://github.com/junyanz/CycleGAN}{Torch}, a machine learning framework for Lua and precursor to PyTorch, however the authors also provided an implementation for \href{https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix}{PyTorch}.

\section{Related Work}
\subsection{Face-off, facial recreation in Keras}

\section{Methodology}
We implemented the PyTorch's model as faithfully as possible in TensorFlow. They were then both trained on a dataset of images of Yosemite taken in both Summer and Winter, from the original paper as well. 

\subsection{PyTorch}
There are currently no implementations of GANs built into the PyTorch framework.
The original implementation that accompanied the paper was in \href{https://github.com/junyanz/CycleGAN}{Torch}, a machine learning framework for Lua and precursor to PyTorch, however the authors also provided an implementation for \href{https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix}{PyTorch}. For this paper we used the PyTorch implementation with the default arguments and hyper-parameters. 

The \textit{generator} is an adaptation of a UNet Network \cite{unet} with skip connections between downscaling and upscaling blocks, as well as a few residual blocks. The skip connections are there such that extra information about images is propagated to the upscaling blocks from the downscaling blocks before the actual downscaling operation is performed. Downscaling blocks are Leaky ReLU layers while upscaling blocks use the normal ReLU activation function.\\ At a high level, the idea is that the downscaling convolutional blocks extract the features of the image, the residual blocks apply the transformation $A \rightarrow B$ to this information, and the upscaling convolutional blocks then generate the image from the transformed information. 

The \textit{discriminator} is simply a ConvNet. It consists of 3 Leaky ReLU layers, the first of which has 64 features.

As per the very definition of CycleGAN, two generators and two discriminators are used.
Each network is optimised using Adam \cite{adam_optimizer}, a common extension of Stochastic Gradient Descent, using \texttt{torch.optim.Adam}.

\subsection{TensorFlow}
TensorFlow provides a suite of tools for GANs in \texttt{tf.contrib.gan}. It has functions for creating, training and evaluating GANs, including both the original model as well as variants such as StarGAN\cite{stargan}, ACGAN\cite{acgan} and of course, CycleGAN.
For CycleGAN, TensorFlow provides \texttt{tf.contrib.gan.cyclegan\_model}. The user of the API must supply the generator and discriminator, and TensorFlow will handle setting up the model to connect the two together.

The generator and discriminator models were created using the high-level \texttt{tf.contrib.layers} counterparts to the PyTorch implementation, including batch normalisation and reflective padding. The functions in \texttt{tf.contrib.gan} were left to their default parameters where possible, which matched those of the original paper.

The images needed to preprocessed so that they were the same size and had pixel values in the range $[-1,1]$.

\section{Results & Discussion}

\section{Limitations}
We observed small, checkerboard artefacts in the output images. Odena et al. describe the cause of these and methods to circumvent it\cite{odena2016deconvolution}.

\section{Further Work}
\begin{figure}
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{dslr2iphone.png}
        \caption{DSLR to phone, back to DSLR.}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{iphone2dslr.png}
        \caption{Phone to DSLR, back to phone.}
    \end{subfigure}
    \label{fig:dslr2iphone}
    \caption{Images converted with CycleGAN to look like they were taken with either a phone or a DSLR. Bokeh gets added in the generated DSLR images, whilst it is stripped in the phone pictures.}
\end{figure}

The TensorFlow model was also trained on a dataset of images of flowers, taken on phones and DSLRs. The results are shown in \ref{fig:dslr2iphone}. The model learnt that DSLR photos typically have a bokeh effect, but unfortunately it also tries to swap out the colours. This may have been caused by one dataset having a particular set of colours more-so than the other, and we speculate this might be fixed by having a larger dataset. Interestingly enough though, the cycle-consistency loss also teaches the network how to reverse the colour swap almost perfectly.

% TensorFlow padding is funny?

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}

\end{document}

